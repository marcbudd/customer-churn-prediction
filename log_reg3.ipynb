{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report, confusion_matrix, precision_score, \\\n",
    "    recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Einlesen der Daten\n",
    "df = pd.read_csv('data/churn_data_encoded.csv')\n",
    "df_test = pd.read_csv('data/churn_data.csv')\n",
    "\n",
    "print(f\"Anzahl der Testdaten: {len(df_test)}\")\n",
    "print(f\"Anzahl der Testdaten nach Entfernung von NaN: {len(df_test.dropna())}\")\n",
    "\n",
    "\n",
    "# Definieren der benutzerdefinierten Bewertungsfunktion und Hilfsfunktionen\n",
    "def custom_score(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    total = len(y_true)\n",
    "    score = (fp + 5 * fn) / total\n",
    "    return score\n",
    "\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    custom = custom_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Custom Score: {custom:.2f}\")\n",
    "    return accuracy, precision, recall, f1, custom\n",
    "\n",
    "\n",
    "def evaluate_classification(X, y, classifier):\n",
    "    custom_scorer = make_scorer(custom_score, greater_is_better=False)\n",
    "    cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=42)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        classifier,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            'accuracy': 'accuracy',\n",
    "            'precision': 'precision',\n",
    "            'recall': 'recall',\n",
    "            'f1': 'f1',\n",
    "            'custom_score': custom_scorer,\n",
    "        }\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Datenaufteilung in Trainings- und Testset, Balancierung und Skalierung\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Balancierte Klassenverteilung im Trainingsset:\\n{y_train_resampled.value_counts()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modelltraining und Evaluierung\n",
    "clf = LogisticRegression(max_iter=2000, solver='lbfgs', random_state=42)\n",
    "scores = evaluate_classification(X_train_resampled_scaled, y_train_resampled, clf)\n",
    "\n",
    "\n",
    "# Hyperparameter-Optimierung mit GridSearchCV\n",
    "def apply_grid_search(classifier, param_grid, X, y, cv=5, scoring='accuracy'):\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=cv, scoring=scoring)\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [5000, 10000],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "best_model = apply_grid_search(LogisticRegression(random_state=42), param_grid, X_train_resampled_scaled,\n",
    "                               y_train_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "# Endgültiges Modelltraining und Evaluierung\n",
    "best_model.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "y_train_pred = best_model.predict(X_train_resampled_scaled)\n",
    "y_train_pred_proba = best_model.predict_proba(X_train_resampled_scaled)[:, 1]\n",
    "\n",
    "print(\"Training classification report:\")\n",
    "print(classification_report(y_train_resampled, y_train_pred))\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_train_resampled, y_train_pred)\n",
    "print(\"Training confusion matrix:\")\n",
    "print(conf_matrix_train)\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(best_model, 'models/logistic_regression_model.pkl')\n",
    "\n",
    "# Testen und Visualisierung\n",
    "# Testdaten vorhersagen\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Ausgabe der Testergebnisse\n",
    "print(\"Test classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Test confusion matrix:\")\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Plotting ROC-Kurve für Testdaten\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting Konfusionsmatrix als Heatmap für Testdaten\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'],\n",
    "            yticklabels=['No Churn', 'Churn'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plotting der vorhergesagten Wahrscheinlichkeiten für Testdaten\n",
    "results = pd.DataFrame({\n",
    "    'True Label': y_test,\n",
    "    'Predicted Probability': y_test_pred_proba\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=np.arange(len(results)), y='Predicted Probability', hue='True Label', data=results, palette='Set1',\n",
    "                s=100, alpha=0.6, edgecolor='k')\n",
    "plt.axhline(0.5, ls='--', color='red')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted Probability of Churn')\n",
    "plt.title('Predicted Probabilities by True Class')\n",
    "plt.legend(title='True Label', labels=['No Churn', 'Churn'])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting: Entscheidungsgrenze\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_scaled)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=2000, solver='lbfgs', random_state=42)\n",
    "log_reg.fit(X_train_pca, y_train_resampled)\n",
    "\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xlabel('PCA Feature 1')\n",
    "    plt.ylabel('PCA Feature 2')\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_decision_boundary(log_reg, X_train_pca, y_train_resampled)\n",
    "\n",
    "# Pairplot für die ersten beiden PCA-Komponenten\n",
    "df_pca = pd.DataFrame(X_train_pca, columns=['PCA1', 'PCA2'])\n",
    "df_pca['Churn'] = y_train_resampled\n",
    "\n",
    "sns.pairplot(df_pca, hue='Churn', markers=[\"o\", \"s\"], palette='Set1')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
